{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed Cross Validated Parameter Search\n",
    "------------------------------------\n",
    "\n",
    "In the previous section we parallelized cross-validated parameter search on a single machine.  In this notebook we do the same exercise, but now on a distributed cluster.  \n",
    "\n",
    "### Requirements\n",
    "\n",
    "This notebook should be run on the provided cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "We train a machine learning model across many parameters with cross validation.  This is slightly more complex than a map, so we use `submit`.  We train a support vector classifier on handwritten digits using cross validation to avoid over-fitting.\n",
    "\n",
    "As before, we start with a sequential solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import ParameterSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Software Environment\n",
    "\n",
    "`cv_params_demo` is a local .py file that defines the functions we are going to use.\n",
    "In the local case, we imported functions from this module.\n",
    "We will run into issues if our worker machines lack the `cv_params_demo.py` file.\n",
    "Distributed computing frameworks have mechanisms to solve this by sending .py files around.\n",
    "In order to skip dealing with this, we are going to include all of the content of that file in this notebook with the `%run` magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run cv_params_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "digits = load_digits()  # Collect Data\n",
    "\n",
    "plt.imshow(digits.data[0].reshape(8, 8),  # Example element\n",
    "           interpolation='nearest', cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': np.logspace(-10, 10, 1001),\n",
    "    'gamma': np.logspace(-10, 10, 1001),\n",
    "    'tol': np.logspace(-4, -1, 4),\n",
    "}\n",
    "\n",
    "param_samples = ParameterSampler(param_grid, 10)\n",
    "\n",
    "list(param_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cv_params_demo import load_cv_split\n",
    "\n",
    "cv_splits = [load_cv_split(i) for i in range(2)]\n",
    "idx, (x_train, x_test, y_train, y_test) = cv_splits[0]\n",
    "x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential cross validated parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "for split in cv_splits:\n",
    "    for params in param_samples:\n",
    "        result = evaluate_one(SVC, params, split)\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results\n",
    "\n",
    "Which regions of parameter space score well?  Can we tell from the results we've computed?  \n",
    "\n",
    "Searching over more parameters would help to improve the intuition we can gain here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cv_params_demo import plot_results\n",
    "\n",
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Distributed parallel cross validated parameter search\n",
    "\n",
    "We can use Spark, dask.distributed, or IPython Parallel to scale our computation across multiple machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_splits = [load_cv_split(i) for i in range(2)]  # Increase the number 2 after parallel computation acheived\n",
    "param_samples = ParameterSampler(param_grid, 10)    # Increase the number 10 after parallel computation acheived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrent.futures solution\n",
    "\n",
    "We load the solution using `concurrent.futures`.  Then we replace the stdlib `concurrent.futures.ThreadPoolExecutor` with an API compatible executor from either `ipyparallel` or `dask.distributed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load solutions/cvgs-1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Solution\n",
    "\n",
    "We load the single-machine solution using the local Spark instance `'local[4]'`.  We replace this SparkContext with a new SparkContext pointing to the cluster instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load solutions/cvgs-2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
